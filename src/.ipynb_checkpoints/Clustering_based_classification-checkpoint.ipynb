{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "civil-friend",
   "metadata": {},
   "source": [
    "# Clustering based classification - Resting State v/s Deep Breathing EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "genetic-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "from progressbar import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "classical-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_train_subject = 23\n",
    "no_of_test_subject = 6\n",
    "elec_name = [\"Time\", \"F3\",\"Fz\",\"F4\",\"FC1\",\"FC2\",\"C3\",\"C4\",\"CP1\",\"CP2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "grand-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_file_RS = '../dataset/Merged_RS_Rejected.txt' #7501 EEG states per subject\n",
    "#source_file_DB = '../dataset/Merged_DB_Rejected.txt' #7501 EEG states per subject\n",
    "\n",
    "source_file_RS = '../dataset/RS_filter.txt'\n",
    "source_file_DB = '../dataset/DB_filter.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medium-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_a, Fp1_a, Fz_a, F3_a, F7_a, FT9_a, FC5_a, FC1_a, C3_a, T7_a, TP9_a, CP5_a, CP1_a, Pz_a, P3_a, P7_a, O1_a, Oz_a, O2_a, P4_a, P8_a, TP10_a, CP6_a, CP2_a, C4_a, T8_a, FT10_a, FC6_a, FC2_a, F4_a, F8_a, Fp2_a = np.loadtxt( \n",
    "    source_file_RS, \n",
    "    skiprows = 1, #If top title row present\n",
    "    unpack = True)\n",
    "Time_b, Fp1_b, Fz_b, F3_b, F7_b, FT9_b, FC5_b, FC1_b, C3_b, T7_b, TP9_b, CP5_b, CP1_b, Pz_b, P3_b, P7_b, O1_b, Oz_b, O2_b, P4_b, P8_b, TP10_b, CP6_b, CP2_b, C4_b, T8_b, FT10_b, FC6_b, FC2_b, F4_b, F8_b, Fp2_b = np.loadtxt( \n",
    "    source_file_DB,\n",
    "    skiprows = 1, #If top title row present\n",
    "    unpack = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "handled-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_1_mat = np.stack((Time_a, F3_a, Fz_a, F4_a, FC1_a, FC2_a, C3_a, C4_a, CP1_a, CP2_a))\n",
    "elec_2_mat = np.stack((Time_b, F3_b, Fz_b, F4_b, FC1_b, FC2_b, C3_b, C4_b, CP1_b, CP2_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-brighton",
   "metadata": {},
   "source": [
    "## Adding values from Resting state for training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "functioning-northwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (23 of 23) |########################| Elapsed Time: 0:14:57 Time:  0:14:57\n",
      "100% (6 of 6) |##########################| Elapsed Time: 0:00:28 Time:  0:00:28\n"
     ]
    }
   ],
   "source": [
    "training_mat_RS = np.zeros(shape=((7501*no_of_train_subject), (len(elec_name)-1)))\n",
    "testing_mat_RS = np.zeros(shape=((7501*no_of_test_subject), (len(elec_name)-1)))\n",
    "\n",
    "#Creating the resting state training matrix\n",
    "for training in progressbar(range (no_of_train_subject)):\n",
    "    for eeg_data in range (7501):\n",
    "        eeg_state = np.array([])\n",
    "        \n",
    "        for i in range (1,len(elec_name)):\n",
    "            eeg_state = np.append(eeg_state, elec_1_mat[i][eeg_data + (7501*training)])\n",
    "     \n",
    "        training_mat_RS = np.delete(training_mat_RS, (0), axis=0)#Make space cause using stack\n",
    "        training_mat_RS = np.append(training_mat_RS,[eeg_state],axis= 0)\n",
    "\n",
    "#Creating the resting state testing matrix\n",
    "for testing in progressbar(range (no_of_test_subject)):\n",
    "    for eeg_data in range (7501):\n",
    "        eeg_state = np.array([])\n",
    "        \n",
    "        for i in range (1,len(elec_name)):\n",
    "            eeg_state = np.append(eeg_state, elec_1_mat[i][eeg_data + (7501*(no_of_train_subject+testing))])\n",
    "     \n",
    "        testing_mat_RS = np.delete(testing_mat_RS, (0), axis=0)#Make space cause using stack\n",
    "        testing_mat_RS = np.append(testing_mat_RS,[eeg_state],axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "useful-parameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.5576  4.148   2.2371 ...  0.02    0.5762 -2.1798]\n",
      " [ 4.5062  4.1746  2.2779 ... -0.1713  0.2835 -2.0773]\n",
      " [ 4.4014  4.1558  2.2934 ... -0.3483 -0.013  -1.9466]\n",
      " ...\n",
      " [-1.6024 -1.1219  0.2574 ...  0.0396 -1.3971 -0.3723]\n",
      " [-1.5881 -1.2278  0.0451 ... -0.0192 -1.3504 -0.3348]\n",
      " [-1.5629 -1.3218 -0.1619 ... -0.0811 -1.294  -0.2997]]\n",
      "(172523, 9)\n",
      "\n",
      "\n",
      "[[-1.2427 -2.0707 -1.4615 ... -2.4415 -1.6264 -0.4128]\n",
      " [-1.1285 -1.9197 -1.5092 ... -2.5059 -1.4007 -0.5299]\n",
      " [-0.981  -1.724  -1.5236 ... -2.5469 -1.1582 -0.6457]\n",
      " ...\n",
      " [-0.0627  0.3412  0.7512 ... -0.8533  1.0798  0.3232]\n",
      " [-0.3371 -0.0115  0.6338 ... -0.3403  0.8194  0.2089]\n",
      " [-0.594  -0.3454  0.5193 ...  0.1764  0.5557  0.1092]]\n",
      "(45006, 9)\n"
     ]
    }
   ],
   "source": [
    "print (training_mat_RS)\n",
    "print (training_mat_RS.shape)\n",
    "print (\"\\n\")\n",
    "print (testing_mat_RS)\n",
    "print (testing_mat_RS.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-planet",
   "metadata": {},
   "source": [
    "## Adding values from Deep Breathing for training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lightweight-integral",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (23 of 23) |########################| Elapsed Time: 0:15:04 Time:  0:15:04\n",
      "100% (6 of 6) |##########################| Elapsed Time: 0:00:28 Time:  0:00:28\n"
     ]
    }
   ],
   "source": [
    "training_mat_DB = np.zeros(shape=((7501*no_of_train_subject), (len(elec_name)-1)))\n",
    "testing_mat_DB = np.zeros(shape=((7501*no_of_test_subject), (len(elec_name)-1)))\n",
    "\n",
    "#print (\"Creating the deep breathing training matrix\")\n",
    "for training in progressbar(range (no_of_train_subject)):\n",
    "    for eeg_data in range (7501):\n",
    "        eeg_state = np.array([])\n",
    "        \n",
    "        for i in range (1,len(elec_name)):\n",
    "            eeg_state = np.append(eeg_state, elec_2_mat[i][eeg_data + (7501*training)])\n",
    "     \n",
    "        training_mat_DB = np.delete(training_mat_DB, (0), axis=0)#Make space cause using stack\n",
    "        training_mat_DB = np.append(training_mat_DB,[eeg_state],axis= 0)\n",
    "\n",
    "#print (\"Creating the deep breathing testing matrix\")        \n",
    "for testing in progressbar(range (no_of_test_subject)):\n",
    "    for eeg_data in range (7501):\n",
    "        eeg_state = np.array([])\n",
    "        \n",
    "        for i in range (1,len(elec_name)):\n",
    "            eeg_state = np.append(eeg_state, elec_2_mat[i][eeg_data + (7501*(no_of_train_subject+testing))])\n",
    "     \n",
    "        testing_mat_DB = np.delete(testing_mat_DB, (0), axis=0)#Make space cause using stack\n",
    "        testing_mat_DB = np.append(testing_mat_DB,[eeg_state],axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "recreational-acrobat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2903 -1.6875 -0.8463 ... -1.2129 -2.5774 -2.2581]\n",
      " [-0.4044 -1.7091 -0.8623 ... -1.0171 -2.4313 -2.0698]\n",
      " [-0.5132 -1.7158 -0.8736 ... -0.7886 -2.2547 -1.8503]\n",
      " ...\n",
      " [-2.1622 -1.5517 -1.0934 ...  0.5436  0.8859  1.0613]\n",
      " [-2.2056 -1.6561 -1.1939 ...  0.4355  0.7919  0.9739]\n",
      " [-2.2286 -1.7409 -1.2843 ...  0.3319  0.7086  0.8929]]\n",
      "(172523, 9)\n",
      "\n",
      "\n",
      "[[-0.519  -0.6456  0.049  ... -0.6515 -1.975  -1.5591]\n",
      " [-0.5353 -0.6268  0.0929 ... -0.7335 -2.0547 -1.7227]\n",
      " [-0.5513 -0.5985  0.1445 ... -0.8096 -2.1229 -1.8727]\n",
      " ...\n",
      " [-3.9314 -3.7511 -2.422  ... -1.0754  0.3369  0.8111]\n",
      " [-3.8149 -3.5907 -2.1473 ... -0.9859  0.0047  0.7802]\n",
      " [-3.6721 -3.4191 -1.8739 ... -0.901  -0.3254  0.7263]]\n",
      "(45006, 9)\n"
     ]
    }
   ],
   "source": [
    "print (training_mat_DB)\n",
    "print (training_mat_DB.shape)\n",
    "print (\"\\n\")\n",
    "print (testing_mat_DB)\n",
    "print (testing_mat_DB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tight-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mat = np.concatenate((training_mat_RS, training_mat_DB))\n",
    "testing_mat = np.concatenate((testing_mat_RS, testing_mat_DB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-overall",
   "metadata": {},
   "source": [
    "## Running Kmeans based Microstate Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "choice-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=8, random_state=0)\n",
    "km = kmeans.fit_predict(training_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "commercial-triangle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of RS =  43.900233592042795 %\n",
      "Training accuracy of DB =  63.97002138845256 %\n"
     ]
    }
   ],
   "source": [
    "count_zero = 0\n",
    "for i in range (7501*no_of_train_subject):\n",
    "    if (km[i] == 0 or km[i] == 1 or km[i] == 2 or km[i] == 3):\n",
    "        count_zero = count_zero + 1\n",
    "        \n",
    "training_acc_RS = (count_zero/(7501*no_of_train_subject)) * 100\n",
    "print (\"Training accuracy of RS = \",training_acc_RS,\"%\")\n",
    "\n",
    "count_one = 0\n",
    "for i in range (7501*no_of_train_subject, len(km)):\n",
    "    if (km[i] == 4 or km[i] == 5 or km[i] == 6 or km[i] == 7):\n",
    "        count_one = count_one + 1\n",
    "        \n",
    "training_acc_DB = (count_one/(7501*no_of_train_subject)) * 100\n",
    "print (\"Training accuracy of DB = \",training_acc_DB,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "informational-disco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy of RS =  42.38323779051682 %\n",
      "Testing accuracy of DB =  63.60707461227392 %\n"
     ]
    }
   ],
   "source": [
    "testing_RS_count = 0\n",
    "centroid = kmeans.cluster_centers_\n",
    "for i in range (7501*no_of_test_subject):\n",
    "    distance2rs_1 = distance.euclidean(centroid[0], testing_mat_RS[i])\n",
    "    distance2rs_2 = distance.euclidean(centroid[1], testing_mat_RS[i])\n",
    "    distance2rs_3 = distance.euclidean(centroid[2], testing_mat_RS[i])\n",
    "    distance2rs_4 = distance.euclidean(centroid[3], testing_mat_RS[i])\n",
    "    \n",
    "    distance2db_1 = distance.euclidean(centroid[4], testing_mat_RS[i])\n",
    "    distance2db_2 = distance.euclidean(centroid[5], testing_mat_RS[i])\n",
    "    distance2db_3 = distance.euclidean(centroid[6], testing_mat_RS[i])\n",
    "    distance2db_4 = distance.euclidean(centroid[7], testing_mat_RS[i])\n",
    "    \n",
    "    if (min(distance2rs_1,distance2rs_2,distance2rs_3,distance2rs_4) <= min(distance2db_1,distance2db_2,distance2db_3,distance2db_4)):\n",
    "        testing_RS_count = testing_RS_count + 1\n",
    "\n",
    "testing_acc_RS = (testing_RS_count/(7501*no_of_test_subject) * 100)\n",
    "print (\"Testing accuracy of RS = \",testing_acc_RS,\"%\")\n",
    "\n",
    "testing_DB_count = 0\n",
    "centroid = kmeans.cluster_centers_\n",
    "for i in range (7501*no_of_test_subject):\n",
    "    \n",
    "    distance2rs_1 = distance.euclidean(centroid[0], testing_mat_DB[i])\n",
    "    distance2rs_2 = distance.euclidean(centroid[1], testing_mat_DB[i])\n",
    "    distance2rs_3 = distance.euclidean(centroid[2], testing_mat_DB[i])\n",
    "    distance2rs_4 = distance.euclidean(centroid[3], testing_mat_DB[i])\n",
    "    \n",
    "    distance2db_1 = distance.euclidean(centroid[4], testing_mat_DB[i])\n",
    "    distance2db_2 = distance.euclidean(centroid[5], testing_mat_DB[i])\n",
    "    distance2db_3 = distance.euclidean(centroid[6], testing_mat_DB[i])\n",
    "    distance2db_4 = distance.euclidean(centroid[7], testing_mat_DB[i])\n",
    "    \n",
    "    \n",
    "    if (min(distance2db_1,distance2db_2,distance2db_3,distance2db_4) <= min(distance2rs_1,distance2rs_2,distance2rs_3,distance2rs_4 )):\n",
    "        testing_DB_count = testing_DB_count + 1\n",
    "\n",
    "testing_acc_DB = (testing_DB_count/(7501*no_of_test_subject) * 100)\n",
    "print (\"Testing accuracy of DB = \",testing_acc_DB,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-advertiser",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
